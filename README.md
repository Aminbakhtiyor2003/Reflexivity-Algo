# Reflexivity-Algo

This strategy, ReflexivityAlgorithm, was my first attempt at building a rules-based framework to navigate market cycles. The goal was straightforward but ambitious: use macroeconomic indicators to infer market regimes and dynamically allocate capital between equities, bonds, and commodities. It was my first time transforming a mental model of how the economy moves markets into code that could be rigorously backtested. That ability to replay history and see hypothetical outcomes was intoxicating but also misleading, as I learned.

The core architecture relied on FRED data such as GDP growth, unemployment, credit spreads, consumer confidence, and the yield curve to classify the environment as bullish, recessionary, or neutral. From there, the strategy would tilt risk exposures accordingly: SPY for equities in growth phases, T-bills and gold in recessions, and a balanced mix in uncertain conditions. Risk management came from a 15% max drawdown limit, trailing high-watermark stops for equities, and a momentum filter to avoid long-duration bonds in downtrends. Rebalancing was set monthly to reduce noise and transaction costs.

The idea worked on paper, but in live thought experiments, its flaws were clear. Economic data is slow and backward-looking. By the time the model rebalanced, much of the new information had already been priced in. My framework was systematically reacting late. A 15% portfolio-level stop was also far too wide. It was designed to allow for macro noise, but in practice, it would have let losses run far beyond what I would tolerate in reality. The model was systematic, yes, but it lacked precision, adaptability, and forward-looking power.

If I were to rebuild this strategy today, several changes would be front and center. First, I would use price-responsive regime detection instead of relying solely on lagging macro data, incorporating market-implied signals such as price momentum, cross-asset correlations, and volatility term structure to infer regime shifts in near-real time. Second, I would experiment with a Kelly Criterion-inspired framework, dynamically sizing exposures based on estimated probabilities of success for each regime. This would help allocate more when the edge is stronger and cut risk when conviction is low, rather than using fixed weights. Third, I would replace the static 15% drawdown threshold with tighter, volatility-adjusted or ATR-based portfolio stops that adapt to changing market conditions. Fourth, I would keep the concept of a circuit breaker that fully de-risks the portfolio when all signals fail, but make it data-driven and tied to multi-asset drawdown clustering or volatility regime breaches. Finally, I would replace the blunt monthly rebalancing with a hybrid approach that reacts immediately to critical triggers while holding steady otherwise, improving responsiveness without overtrading.

This first algorithm was rudimentary and reactive, but it was foundational. It forced me to confront the gap between theoretical frameworks and real-world implementation, where latency, noise, and human behavior distort clean models. It sparked my search for better ways to identify regimes, not by reading yesterday’s data but by interpreting the market’s own language in real time.